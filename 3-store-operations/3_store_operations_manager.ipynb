{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3. Store Operations Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we show you how to create your third and last sub-agent on Amazon Bedrock Agents.\n",
    "\n",
    "This agent identifies inefficient store processes and analyzes peak vs. off-peak store traffic patterns to optimize staffing allocation.\n",
    "\n",
    "This agent can also provide retail efficiency tips based on the search of videos embedded in Amazon Bedrock Knowledge Bases using insights generated with [Amazon Bedrock Data Automation (BDA)](https://aws.amazon.com/bedrock/bda/).\n",
    "BDA automates the generation of useful insights from unstructured multimodal content such as documents, images, audio, and video for your AI-powered applications.\n",
    "\n",
    "The following represents the piece of architecture that will be built on this module.\n",
    "\n",
    "![Architecture](img/peak_load_agent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before you start, please ensure you selected the notebook kernel as Python 3, and run the following cell to make sure that your boto3 version is the latest one.\n",
    "\n",
    "If not, return no [notebook 1](../1-energy-forecast/1_forecasting_agent.ipynb) and run Setup block again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install latest dependencies\n",
    "!python3 -m pip install --upgrade \"boto3>=1.37.4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze | grep boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y numpy\n",
    "!pip install \"numpy==1.26.4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get your workshop ID / resource suffix. If not found, return to [notebook 1](../1-energy-forecast/1_forecasting_agent.ipynb) and run the Setup block again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_workshop_id():\n",
    "    workshop_id_file = '../.workshop_id'\n",
    "    if os.path.exists(workshop_id_file):\n",
    "        with open(workshop_id_file, 'r') as f:\n",
    "            return f.read().strip()\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "workshop_id = get_workshop_id()\n",
    "resource_suffix = f\"{workshop_id}\"\n",
    "\n",
    "if workshop_id is None:\n",
    "    print(\"No workshop ID found. Please run the Setup script in notebook 1.\")\n",
    "else:\n",
    "    print(\"Your resource suffix is\", resource_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent\n",
    "\n",
    "On this section we declare global variables that will be act as helpers during entire notebook and we will start to create out second agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os\n",
    "import json, uuid\n",
    "import random\n",
    "import time\n",
    "sts_client = boto3.client('sts')\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "session = sagemaker.Session()\n",
    "bucket_name = session.default_bucket()\n",
    "\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "\n",
    "agent_foundation_model = [\n",
    "    'anthropic.claude-3-5-sonnet-20240620-v1:0',\n",
    "    'anthropic.claude-3-sonnet-20240229-v1:0',\n",
    "    'anthropic.claude-3-haiku-20240307-v1:0',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ops_agent_name = f\"store-ops-{resource_suffix}\"\n",
    "\n",
    "store_ops_lambda_name = f\"fn-store-ops-{resource_suffix}\"\n",
    "\n",
    "store_ops_agent_role_name = f'AmazonBedrockExecutionRoleForAgents_{store_ops_agent_name}'\n",
    "\n",
    "dynamodb_table = f\"{store_ops_agent_name}-table\"\n",
    "dynamodb_pk = \"customer_id\"\n",
    "dynamodb_sk = \"item_id\"\n",
    "\n",
    "dynamoDB_args = [dynamodb_table, dynamodb_pk, dynamodb_sk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing helper functions\n",
    "\n",
    "On following section, we're adding `bedrock_agent_helper.py` on Python path, so the files can be recognized and their functionalities can be invoked.\n",
    "\n",
    "Now, you're going to import from helper classes `bedrock_agent_helper.py`.\n",
    " \n",
    "Those files contain helper classes totally focused on make labs experience smoothly. \n",
    "\n",
    "All interactions with Bedrock will be handled by these classes.\n",
    "\n",
    "Following are methods that you're going to invoke on this lab:\n",
    "\n",
    "On `agents.py`:\n",
    "- `create_agent`: Create a new agent and respective IAM roles\n",
    "- `add_action_group_with_lambda`: Create a lambda function and add it as an action group for a previous created agent\n",
    "- `create_agent_alias`: Create an alias for this agent\n",
    "- `invoke`: Execute agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \".\")\n",
    "sys.path.insert(1, \"..\")\n",
    "\n",
    "from utils.bedrock_agent_helper import (\n",
    "    AgentsForAmazonBedrock\n",
    ")\n",
    "agents = AgentsForAmazonBedrock()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Agent\n",
    "Create the Store Operations Manager agent that will have an action group to handle resource allocation and inefficient process detection.\n",
    "\n",
    "For this agent we will use the following instructions:\n",
    "```\n",
    "You are a Store Operations Manager Bot that optimizes retail operations by analyzing store department data and staffing schedules.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Retrieving data from store departments\n",
    "2. Identifying inefficient processes during peak hours and reallocating staff to other departments\n",
    "3. Recommending schedule adjustments\n",
    "\n",
    "Response style:\n",
    "- Be precise and analytical\n",
    "- Use clear, practical language\n",
    "- Focus on actionable recommendations\n",
    "- Support suggestions with data\n",
    "- Be concise yet thorough\n",
    "- Do not request information that can be retrieved from store systems\n",
    "```\n",
    "\n",
    "And we will make the following tool available to the agent:\n",
    "- `detect_peak_traffic`: detect traffic peaks in store departments\n",
    "- `detect_inefficient_processes`: detect inefficient processes in departments\n",
    "- `redistribute_staffing`: reduce/increase staffing allocation for a specific department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ops_agent = agents.create_agent(\n",
    "    store_ops_agent_name,\n",
    "    \"\"\"You are a store operations manager bot. \n",
    "    You can retrieve information from store departments and Knowledge Bases, \n",
    "    identify inefficient processes and peak traffic patterns and suggest staffing reallocations.\n",
    "    \"\"\",\n",
    "    \"\"\"You are a Store Operations Manager Bot that optimizes retail operations\n",
    "by analyzing store department data, video information from Knowledge Bases and staffing schedules.\n",
    "\n",
    "Your capabilities include:\n",
    "1. Retrieving data from store departments and Knowledge Bases\n",
    "2. Identifying inefficient processes during peak hours and reallocating staff to other departments\n",
    "3. Recommending schedule adjustments\n",
    "4. Identify inefficient operational patterns inside stores and recommend optimization tips\n",
    "\n",
    "Response style:\n",
    "- Be precise and analytical\n",
    "- Use clear, practical language\n",
    "- Focus on actionable recommendations\n",
    "- Support suggestions with data\n",
    "- Be concise yet thorough\n",
    "- Do not request information that can be retrieved from store systems\n",
    "    \"\"\",\n",
    "    agent_foundation_model\n",
    ")\n",
    "\n",
    "store_ops_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating BDA project\n",
    "To start a BDA job, you need a BDA project, which organizes both standard and custom output configurations. This project is reusable, allowing you to apply the same configuration to process multiple video/audio files that share the same settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bda_client = boto3.client('bedrock-data-automation', region_name=region)\n",
    "bda_runtime_client = boto3.client('bedrock-data-automation-runtime', region_name=region)\n",
    "s3_client = boto3.client('s3', region_name=region)\n",
    "\n",
    "kb_bucket_name = f'store-ops-kb-datasource-{account_id}-{resource_suffix}'\n",
    "\n",
    "s3_client.create_bucket(\n",
    "    Bucket=kb_bucket_name,\n",
    "    CreateBucketConfiguration={'LocationConstraint': region} # Comment this out if you are in us-east-1\n",
    ")\n",
    "\n",
    "bucket_name_input = f's3://{bucket_name}/bda/input'      # DBA input path\n",
    "bucket_name_output = f's3://{bucket_name}/bda/output'    # DBA output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name= f'bda-kb-project-{resource_suffix}'\n",
    "\n",
    "# delete project if it already exists\n",
    "projects_existing = [project for project in bda_client.list_data_automation_projects(projectStageFilter='ALL')[\"projects\"] if project[\"projectName\"] == project_name]\n",
    "if len(projects_existing) >0:\n",
    "    print(f\"Deleting existing project: {projects_existing[0]}\")\n",
    "    bda_client.delete_data_automation_project(projectArn=projects_existing[0][\"projectArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = bda_client.create_data_automation_project(\n",
    "    projectName=project_name,\n",
    "    projectDescription='BDA video processing project',\n",
    "    projectStage='DEVELOPMENT',\n",
    "    standardOutputConfiguration={\n",
    "        \"video\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\",\n",
    "                    \"types\": [\"CONTENT_MODERATION\", \"TEXT_DETECTION\", \"TRANSCRIPT\"]\n",
    "                },\n",
    "                \"boundingBox\": {\"state\": \"ENABLED\"}\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"VIDEO_SUMMARY\", \"CHAPTER_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        },\n",
    "        \"audio\": {\n",
    "            \"extraction\": {\n",
    "                \"category\": {\n",
    "                    \"state\": \"ENABLED\", \n",
    "                    \"types\": [\"AUDIO_CONTENT_MODERATION\", \"TOPIC_CONTENT_MODERATION\", \"TRANSCRIPT\"]\n",
    "                }\n",
    "            },\n",
    "            \"generativeField\": {\n",
    "                \"state\": \"ENABLED\",\n",
    "                \"types\": [\"AUDIO_SUMMARY\", \"TOPIC_SUMMARY\", \"IAB\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_project_arn = response.get(\"projectArn\")\n",
    "print(\"BDA kb project ARN:\", kb_project_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start BDA tasks\n",
    "We will now invoke the BDA API to process the uploaded audio file. You need to provide the BDA project ARN that we created at the beginning of the lab and specify an S3 location where BDA will store the output results.\n",
    "\n",
    "For a complete API reference for invoke a BDA async task, refer to this [document](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-data-automation-runtime/client/invoke_data_automation_async.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "# Create video directory if it doesn't exist\n",
    "video_dir = \"./video\"\n",
    "Path(video_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# List of video URLs and their target filenames - these are retail store operation videos\n",
    "videos = [\n",
    "    (\"store_checkout.MOV\", \"https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/1031afa5-be84-4a6a-9886-4e19ce67b9c2/video/store_checkout.MOV\"),\n",
    "    (\"store_displays.MOV\", \"https://ws-assets-prod-iad-r-pdx-f3b3f9f1a7d6a3d0.s3.us-west-2.amazonaws.com/1031afa5-be84-4a6a-9886-4e19ce67b9c2/video/store_displays.MOV\")\n",
    "]\n",
    "\n",
    "# Download the videos\n",
    "for filename, url in videos:\n",
    "    output_path = os.path.join(video_dir, filename)\n",
    "    print(f\"Downloading {filename}...\")\n",
    "    \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(output_path, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Successfully downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload video files\n",
    "import os\n",
    "from IPython.display import JSON, IFrame, Video, display, clear_output\n",
    "from datetime import datetime\n",
    "import time\n",
    "from time import sleep\n",
    "\n",
    "path=\"./video\"\n",
    "        \n",
    "for root,dirs,files in os.walk(path):\n",
    "    for file in files:\n",
    "        file_to_upload = os.path.join(root,file)\n",
    "                       \n",
    "        file_input = f'bda/input/video/{file}'\n",
    "        \n",
    "        print(f\"uploading file {file_to_upload} to {bucket_name}\")\n",
    "        s3_client.upload_file(file_to_upload,bucket_name,file_input)\n",
    "\n",
    "        output_name = f'bda/output/'\n",
    "        # Start BDA task video\n",
    "        response_vid = bda_runtime_client.invoke_data_automation_async(\n",
    "            inputConfiguration={'s3Uri':  f\"s3://{bucket_name}/{file_input}\"},\n",
    "            outputConfiguration={'s3Uri': f\"s3://{bucket_name}/{output_name}\"},\n",
    "            dataAutomationProfileArn= f'arn:aws:bedrock:{region}:{account_id}:data-automation-profile/us.data-automation-v1',\n",
    "            dataAutomationConfiguration={\n",
    "                'dataAutomationProjectArn':kb_project_arn,\n",
    "                #'dataAutomationArn': kb_project_arn,\n",
    "                'stage': 'DEVELOPMENT'\n",
    "            })\n",
    "\n",
    "        invocation_video_arn = response_vid.get(\"invocationArn\")\n",
    "        print(\"BDA video task started:\", invocation_video_arn)\n",
    "\n",
    "        statusVideo, status_vid_response = None, None\n",
    "        \n",
    "        while statusVideo not in [\"Success\",\"ServiceError\",\"ClientError\"]:\n",
    "            status_vid_response = bda_runtime_client.get_data_automation_status(\n",
    "                invocationArn=invocation_video_arn\n",
    "            )\n",
    "            statusVideo = status_vid_response.get(\"status\")\n",
    "    \n",
    "            clear_output(wait=True)\n",
    "            print(f\"{datetime.now().strftime('%H:%M:%S')} : \"\\\n",
    "              f\"BDA kb video task: {statusVideo} \")\n",
    "            time.sleep(5)\n",
    "\n",
    "\n",
    "        output_vid_config = status_vid_response.get(\"outputConfiguration\",{}).get(\"s3Uri\")\n",
    "        print(\"Ouput configuration file:\", output_vid_config)\n",
    "\n",
    "        # prep BDA output for the kb\n",
    "        out_vid_loc = status_vid_response['outputConfiguration']['s3Uri'].split(\"/job_metadata.json\", 1)[0].split(bucket_name+\"/\")[1]\n",
    "        out_vid_loc += \"/0/standard_output/0/result.json\"\n",
    "        print(out_vid_loc)\n",
    "        s3_client.download_file(bucket_name, out_vid_loc, f'result_vid_{file}.json')\n",
    "        \n",
    "        kb_file = f'data/result_vid_{file}_kb.json'\n",
    "        local_file =f'result_vid_{file}.json'\n",
    "        \n",
    "        #filter_json(f'result_vid_{file}.json', local_file)\n",
    "\n",
    "        print(f\"uploading file {local_file} to KB bucket {kb_bucket_name}\")\n",
    "        s3_client.upload_file(local_file, kb_bucket_name, kb_file )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the parent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Add both current and parent directories to sys.path\n",
    "sys.path.insert(0, current_dir)\n",
    "sys.path.insert(1, parent_dir)\n",
    "\n",
    "from utils.knowledge_base import BedrockKnowledgeBase\n",
    "\n",
    "knowledge_base_name = 'store-ops-kb-video'\n",
    "knowledge_base_description = \"Knowledge Base containing store operations video data that show various checkout and display processes inside a retail store\"\n",
    "\n",
    "data=[{\"type\": \"S3\", \"bucket_name\": kb_bucket_name}]\n",
    "# For multi-modal RAG While instantiating BedrockKnowledgeBase, pass multi_modal= True and choose the parser you want to use\n",
    "\n",
    "knowledge_base = BedrockKnowledgeBase(\n",
    "    kb_name= knowledge_base_name,\n",
    "    kb_description=knowledge_base_description,\n",
    "    data_sources=data,\n",
    "    multi_modal= True,\n",
    "    parser= 'BEDROCK_DATA_AUTOMATION', #'BEDROCK_FOUNDATION_MODEL'\n",
    "    chunking_strategy = \"FIXED_SIZE\", \n",
    "    suffix = f'{resource_suffix}-f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the knowledge Bases ingestion job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that the kb is available\n",
    "time.sleep(30)\n",
    "\n",
    "# sync knowledge base\n",
    "knowledge_base.start_ingestion_job()\n",
    "\n",
    "time.sleep(30)\n",
    "# keep the kb_id for invocation later in the invoke request\n",
    "kb_id = knowledge_base.get_knowledge_base_id()\n",
    "%store kb_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associating Knowledge Base to agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Associate knowledge base\n",
    "kb_response = agents.associate_kb_with_agent(\n",
    "    agent_id=store_ops_agent[0],\n",
    "    description=\"This knowledge base contains relevant information for the agent to find operational inefficiencies inside a retail store\",\n",
    "    kb_id=kb_id\n",
    ")\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Action Group\n",
    "\n",
    "On this session, we're going create an action group to handle the store operations management and associate it with our agent. To do so, we will first create a Lambda function code to fulfill the execution of the agent's actions Next we will define the actions available actions that an agent can take using function details. Similar to the previous agent, you can also define the actions available using OpenAPI Schema.\n",
    "\n",
    "#### Creating Lambda function\n",
    "First let's create the lambda function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile store_operations.py\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import random\n",
    "\n",
    "from boto3.dynamodb.conditions import Key, Attr\n",
    "\n",
    "dynamodb_resource = boto3.resource('dynamodb')\n",
    "dynamodb_table = os.getenv('dynamodb_table')\n",
    "dynamodb_pk = os.getenv('dynamodb_pk')\n",
    "dynamodb_sk = os.getenv('dynamodb_sk')\n",
    "\n",
    "def get_named_parameter(event, name):\n",
    "    return next(item for item in event['parameters'] if item['name'] == name)['value']\n",
    "    \n",
    "def populate_function_response(event, response_body):\n",
    "    return {'response': {'actionGroup': event['actionGroup'], 'function': event['function'],\n",
    "                'functionResponse': {'responseBody': {'TEXT': {'body': str(response_body)}}}}}\n",
    "\n",
    "def put_dynamodb(table_name, item):\n",
    "    table = dynamodb_resource.Table(table_name)\n",
    "    \n",
    "    resp = table.update_item(\n",
    "        Key={'customer_id': item['customer_id'],\n",
    "             'item_id': item['item_id']},\n",
    "        UpdateExpression='SET #attr1 = :val1',\n",
    "        ExpressionAttributeNames={'#attr1': 'staffing'},\n",
    "        ExpressionAttributeValues={':val1':  item['staffing']}\n",
    "    )\n",
    "    return resp\n",
    "\n",
    "def read_dynamodb(\n",
    "    table_name: str, \n",
    "    pk_field: str,\n",
    "    pk_value: str,\n",
    "    sk_field: str=None, \n",
    "    sk_value: str=None,\n",
    "    attr_key: str=None,\n",
    "    attr_val: str=None\n",
    "):\n",
    "    try:\n",
    "\n",
    "        table = dynamodb_resource.Table(table_name)\n",
    "        # Create expression\n",
    "        if sk_field:\n",
    "            key_expression = Key(pk_field).eq(pk_value) & Key(sk_field).eq(sk_value)\n",
    "        else:\n",
    "            key_expression = Key(pk_field).eq(pk_value)\n",
    "\n",
    "        if attr_key:\n",
    "            attr_expression = Attr(attr_key).eq(attr_val)\n",
    "            query_data = table.query(\n",
    "                KeyConditionExpression=key_expression,\n",
    "                FilterExpression=attr_expression\n",
    "            )\n",
    "        else:\n",
    "            query_data = table.query(\n",
    "                KeyConditionExpression=key_expression\n",
    "            )\n",
    "        \n",
    "        return query_data['Items']\n",
    "    except Exception:\n",
    "        print(f'Error querying table: {table_name}.')\n",
    "\n",
    "\n",
    "def detect_peak_traffic(store_id):\n",
    "    return read_dynamodb(dynamodb_table, \n",
    "                       dynamodb_pk, \n",
    "                       store_id, \n",
    "                       attr_key=\"peak\", attr_val=\"True\")\n",
    "\n",
    "def detect_inefficient_processes(store_id):\n",
    "    return read_dynamodb(dynamodb_table, \n",
    "                       dynamodb_pk, \n",
    "                       store_id,\n",
    "                       attr_key=\"essential\", attr_val=\"False\")\n",
    "\n",
    "                \n",
    "def redistribute_staffing(store_id, department_id, staffing):\n",
    "    item = {\n",
    "        'customer_id': store_id,\n",
    "        'item_id': department_id,\n",
    "        'staffing': staffing\n",
    "    }\n",
    "    resp = put_dynamodb(dynamodb_table, item)\n",
    "    return f\"Department {department_id} has been updated. New staffing level: {staffing}\"\n",
    "\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    print(event)\n",
    "    \n",
    "    # name of the function that should be invoked\n",
    "    function = event.get('function', '')\n",
    "\n",
    "    # parameters to invoke function with\n",
    "    parameters = event.get('parameters', [])\n",
    "    \n",
    "    store_id = get_named_parameter(event, \"store_id\")\n",
    "\n",
    "    if function == 'detect_peak_traffic':    \n",
    "        result = detect_peak_traffic(store_id)\n",
    "    elif function == 'detect_inefficient_processes':    \n",
    "        result = detect_inefficient_processes(store_id)\n",
    "    elif function == 'redistribute_staffing':    \n",
    "        department_id = get_named_parameter(event, \"department_id\")\n",
    "        staffing = get_named_parameter(event, \"staffing\")\n",
    "        result = redistribute_staffing(store_id, department_id, staffing)\n",
    "    else:\n",
    "        result = f\"Error, function '{function}' not recognized\"\n",
    "\n",
    "    response = populate_function_response(event, result)\n",
    "    print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining available actions\n",
    "Now it's time to define the actions that can be taken by the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_def = [\n",
    "    {\n",
    "        \"name\": \"detect_peak_traffic\",\n",
    "        \"description\": \"\"\"detect traffic peaks in store departments\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"store_id\": {\n",
    "                            \"description\": \"The ID of the store\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"detect_inefficient_processes\",\n",
    "        \"description\": \"\"\"detect inefficient processes in departments\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"store_id\": {\n",
    "                            \"description\": \"The ID of the store\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"redistribute_staffing\",\n",
    "        \"description\": \"\"\"reduce/increase staffing allocation for a specific department\"\"\",\n",
    "        \"parameters\": {\n",
    "                        \"store_id\": {\n",
    "                            \"description\": \"The ID of the store\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"department_id\": {\n",
    "                            \"description\": \"Department that will be updated\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        },\n",
    "                        \"staffing\": {\n",
    "                            \"description\": \"new staffing level\",\n",
    "                            \"required\": True,\n",
    "                            \"type\": \"string\"\n",
    "                        }\n",
    "                    }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Associating action group to agent\n",
    "Finally, we can associate a new action group with our previously created agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agents.add_action_group_with_lambda(\n",
    "    agent_name=store_ops_agent_name,\n",
    "    lambda_function_name=store_ops_lambda_name,\n",
    "    source_code_file=\"store_operations.py\",\n",
    "    agent_functions=functions_def,\n",
    "    agent_action_group_name=\"store_operations_actions\",\n",
    "    agent_action_group_description=\"Function to get traffic peaks, inefficient processes, and redistribute staffing for a store\",\n",
    "    dynamo_args=dynamoDB_args\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data to DynamoDB\n",
    "\n",
    "Now that we've created our agent, let's load some generated data to DynamoDB. That will allow the agent to interact with some live data to perform actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"3_store_sample_data.json\") as f:\n",
    "    table_items = [json.loads(line) for line in f]\n",
    "\n",
    "agents.load_dynamodb(dynamodb_table, table_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that data was loaded on DynamoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agents.query_dynamodb(dynamodb_table, dynamodb_pk, '1', dynamodb_sk, \"1\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agent\n",
    "\n",
    "Now, let's run some tests on the agent we just created to make sure it's working. To do so we will use our test alias: `TSTALIASID` which allows you to invoke a draft version of your agent\n",
    "\n",
    "### Testing inefficient process detection\n",
    "First let's ask a question related to inefficient process detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"What departments have inefficient processes? My store id is 2\", \n",
    "    store_ops_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing traffic optimization\n",
    "Next let's ask the agent to optimize store operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"Where are my traffic peaks? How can I optimize my store operations? My store id is 1\", \n",
    "    store_ops_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing staffing reallocation\n",
    "Finally, let's ask the agent to do some staffing reallocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = agents.invoke(\n",
    "    \"\"\"Can you change my staffing allocation? My store id is 2, department id is 2 and I want to reduce staffing to 1\"\"\", \n",
    "    store_ops_agent[0], enable_trace=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store environment variables to be used on next notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Agent with KB\n",
    "\n",
    "The following function takes some time to retrieve the video file from the Knowledge Bases, so please be patient for it to finish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "time.sleep(30)\n",
    "response = agents.invoke(\n",
    "    #\"give me a list of videos related with checkout operations\", \n",
    "    \"what retail operations efficiency advice can you give based on the videos showing checkout processes in the store, please include the original knowledge base source\",\n",
    "    #\"what retail operations efficiency advice can you give based on the videos related to store displays\",\n",
    "    store_ops_agent[0], \n",
    "    enable_trace=True,\n",
    "    #end_session=True\n",
    ")\n",
    "print(\"====================\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the store operations video clip referred by the agent in citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video path and timestamps from the response\n",
    "import re\n",
    "from IPython.display import HTML\n",
    "from utils.knowledge_base_operators import play_video_from_bedrock_response\n",
    "\n",
    "play_video_from_bedrock_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create alias\n",
    "\n",
    "As you can see, you can use your agent with the `TSTALIASID` to complete tasks. \n",
    "However, for multi-agents collaboration it is expected that you first test your agent and only use it once it is fully functional. \n",
    "Therefore to use an agent as a sub-agent in a multi-agent collaboration you first need to create an agent alias and connect it to a new version. \n",
    "\n",
    "Since we've tested and validated our agent, let's now create an alias for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ops_agent_alias_id, store_ops_agent_alias_arn = agents.create_agent_alias(\n",
    "    store_ops_agent[0], 'v1'\n",
    ")\n",
    "store_ops_agent_id = store_ops_agent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ops_agent_arn = agents.get_agent_arn_by_name(store_ops_agent_name)\n",
    "store_ops_dynamodb = dynamodb_table\n",
    "store_ops_kb = knowledge_base_name\n",
    "\n",
    "%store store_ops_agent_arn\n",
    "%store store_ops_agent_alias_arn\n",
    "%store store_ops_agent_alias_id\n",
    "%store store_ops_lambda_name\n",
    "%store store_ops_agent_name\n",
    "%store store_ops_agent_id\n",
    "%store store_ops_dynamodb\n",
    "%store store_ops_kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_ops_agent_arn, store_ops_agent_alias_arn, store_ops_agent_alias_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Congratulations! We've now created all of our sub-agents. Next we will create our supervisor agent to do the orchestration between the sub-agents"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}